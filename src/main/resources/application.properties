spring.application.name=kunsharedemo
server.servlet.context-path=/kunsharedemo
#spring.main.allow-bean-definition-overriding=true

spring.profile.active=dev

#禁用aop,设置为false,表示关闭aop功能（这个配置很少用）
#spring.aop.auto=false
#spring.sleuth.scheduled.enabled=false

## =============== spring cloud config   =======================
## 外部源配置是否可被覆盖
spring.cloud.config.allowOverride=false
## 外部源配置是否不覆盖任何源
spring.cloud.config.overrideNone=false
## 外部源配置是否可覆盖本地属性
spring.cloud.config.overrideSystemProperties=true

# =============== 日志  =======================
# 将mapper接口所在包的日志级别改成debug，可以在控制台打印sql
logging.config=classpath:log4j2-spring.properties
logging.level.com.example.demo.mapper=debug
logging.level.org.springframework.cloud.task=DEBUG

management.server.port=10001
management.server.servlet.context-path=/${spring.application.name}
#开启所有端点的访问
management.endpoints.web.exposure.include=*
#动态刷新配置 ---需要忽略权限拦截（1.5.X版本使用）
#management.security.enabled=false
#management.endpoint.prometheus.enabled=true


# =============== eureka  =======================
# 集成eureka注册中心
eureka.client.serviceUrl.defaultZone=http://admin:123456@localhost:1001/eureka/
eureka.client.register-with-eureka=false
# 关闭eureka客户端
eureka.client.enabled=false

# =============== zipkin  =======================
spring.zipkin.base-url=http://192.168.3.105:9411
spring.zipkin.kafka.topic=zipkin
# 设置采样比例为100%
spring.sleuth.sampler.probability=1.0

#暂时关闭zipkin
spring.zipkin.enabled=false

# =============== feign  =======================
feign.hystrix.enabled=true
#定制化配置
#feign.client.config.kunwebdemo.requestInterceptors[0]=cn.com.kun.springframework.springcloud.feign.config.MyLocalFeignRequestInterceptor

# feign扩展--本地调试开关
feign.localinvoke.enabled=true
feign.localinvoke.url.kunwebdemo=http://127.0.0.1:8091


# =============== hystrix  =======================
hystrix.threadpool.HystrixDemoService-method11.maximumSize=10
hystrix.threadpool.HystrixDemoService-method11.allowMaximumSizeToDivergeFromCoreSize=true

# =============== spring cloud alibaba sentinel  =======================

#连接sentinel的dashboard
spring.cloud.sentinel.transport.dashboard=127.0.0.1:8070
#client-ip: 192.168.0.9:9000
#spring.cloud.sentinel.transport.clientIp=192.168.0.9:9000
#注意这里的端口默认是8719  如果8719被占用会自动+1 无需当心.可以不指定
#spring.cloud.sentinel.transport.port=8719
#spring.cloud.sentinel.transport.eager=true

#sentinel-rule.flow-rule.SENDCHANNEL_DX.resource=SENDCHANNEL_DX
sentinel-rule.flow-rule.SENDCHANNEL_DX.count=5
sentinel-rule.flow-rule.SENDCHANNEL_DX.yellowLineThreshold=3
#sentinel-rule.flow-rule.SENDCHANNEL_WX.resource=SENDCHANNEL_WX
sentinel-rule.flow-rule.SENDCHANNEL_WX.count=10
sentinel-rule.flow-rule.SENDCHANNEL_WX.yellowLineThreshold=5
#定义具体的业务场景限流值
sentinel-rule.flow-rule.SentinelFlowControlDemoService.count=5

sentinel-rule.degrade-rule.SENDCHANNEL_DX.count=5
sentinel-rule.degrade-rule.SENDCHANNEL_DX.yellowLineThreshold=3
sentinel-rule.degrade-rule.SENDCHANNEL_WX.count=10
sentinel-rule.degrade-rule.SENDCHANNEL_WX.yellowLineThreshold=5

# 结合sentinel控制Kafka消费速度（这部分属于业务参数）
kafka-consumer-speed.middleAndLowEnabled=true
#高优先级线程睡眠时间-红区：1秒
kafka-consumer-speed.highSleepTimeWhenRed=1000
#kafka-consumer-speed.highSleepTimeWhenYellow=0
#kafka-consumer-speed.highSleepTimeWhenGreen=0
kafka-consumer-speed.middleSleepTimeWhenRed=10000
kafka-consumer-speed.middleSleepTimeWhenYellow=5000
#kafka-consumer-speed.middleSleepTimeWhenGreen=0
kafka-consumer-speed.lowSleepTimeWhenRed=20000
kafka-consumer-speed.lowSleepTimeWhenYellow=10000
#kafka-consumer-speed.lowSleepTimeWhenGreen=0

# =================== Spring Batch ===================
#是否自动执行定义的Job，默认是true
spring.batch.job.enabled=false

# Spring Cloud Task
# 禁用Spring Cloud Task自动建表
#spring.cloud.task.initialize.enable=false
# task执行完毕后关闭上下文（一般不需要这样的操作）
#spring.cloud.task.closecontext_enabled=true
# 禁用Spring Cloud Task自动配置
#spring.cloud.task.autoconfiguration.enabled=false
#spring.cloud.task.batch.listener.enable=false

# =================== mysql ===================
# 应用主库（quartz专用的数据源）
spring.datasource.quartzDataSource.driverClassName=com.mysql.jdbc.Driver
spring.datasource.quartzDataSource.url=jdbc:mysql://127.0.0.1:3306/test?useUnicode=true&characterEncoding=utf-8
spring.datasource.quartzDataSource.username=root
spring.datasource.quartzDataSource.password=e5906dd7a635176c108e4ba850f6bedc
spring.datasource.quartzDataSource.type=com.alibaba.druid.pool.DruidDataSource

# 连接池的配置信息
# 初始化大小，最小，最大
spring.datasource.quartzDataSource.initialSize=10
spring.datasource.quartzDataSource.minIdle=20
spring.datasource.quartzDataSource.maxActive=50
# 配置获取连接等待超时的时间
spring.datasource.quartzDataSource.maxWait=60000
# 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
spring.datasource.quartzDataSource.timeBetweenEvictionRunsMillis=60000
# 配置一个连接在池中最小生存的时间，单位是毫秒
spring.datasource.quartzDataSource.minEvictableIdleTimeMillis=300000
spring.datasource.quartzDataSource.validationQuery=SELECT 1 FROM DUAL
spring.datasource.quartzDataSource.testWhileIdle=true
spring.datasource.quartzDataSource.testOnBorrow=false
spring.datasource.quartzDataSource.testOnReturn=false
# 打开PSCache，并且指定每个连接上PSCache的大小
spring.datasource.quartzDataSource.poolPreparedStatements=true
spring.datasource.quartzDataSource.maxPoolPreparedStatementPerConnectionSize=20
# 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙
spring.datasource.quartzDataSource.filters=stat,wall,log4j
# 通过connectProperties属性来打开mergeSql功能；慢SQL记录
spring.datasource.quartzDataSource.connectionProperties=password=${spring.datasource.quartzDataSource.password};druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000
#数据库密码解密回调
spring.datasource.quartzDataSource.passwordCallbackClassName=cn.com.kun.config.mysql.DBPasswordCallback

# 主数据源
# Springboot2.1.2默认引入的mysql版本version是8.0.13，其driver-class-name为com.mysql.cj.jdbc.Driver
spring.datasource.url=jdbc:mysql://127.0.0.1:3306/test?useUnicode=true&characterEncoding=UTF-8&serverTimezone=UTC&useSSL=false
spring.datasource.username=root
spring.datasource.password=12345678
spring.datasource.driver-class-name=com.mysql.jdbc.Driver
spring.datasource.type=com.alibaba.druid.pool.DruidDataSource
# druid (springboot2.x，下面的这些配置无效，必须要用spring.datasource.druid开头)
spring.datasource.filters=stat
spring.datasource.maxActive=60
spring.datasource.initialSize=15
spring.datasource.maxWait=60000
spring.datasource.minIdle=35
spring.datasource.timeBetweenEvictionRunsMillis=60000
spring.datasource.minEvictableIdleTimeMillis=300000
spring.datasource.validationQuery=select 'x'
spring.datasource.testWhileIdle=true
spring.datasource.testOnBorrow=false
spring.datasource.testOnReturn=false
spring.datasource.poolPreparedStatements=true
spring.datasource.maxOpenPreparedStatements=20

# druid
#初始化时建立物理连接的个数
spring.datasource.druid.initial-size=8
#最小连接池数量
spring.datasource.druid.min-idle=16
#最大连接池数量
spring.datasource.druid.max-active=40
#获取连接时最大等待时间
spring.datasource.druid.max-wait=60000
#配置监控页面访问登录名称
spring.datasource.druid.stat-view-servlet.login-username=admin
#配置监控页面访问密码
spring.datasource.druid.stat-view-servlet.login-password=admin
#是否开启慢sql查询监控
spring.datasource.druid.filter.stat.log-slow-sql=true
#慢SQL执行时间
spring.datasource.druid.filter.stat.slow-sql-millis=1

#持久化到数据库方式
spring.quartz.job-store-type=jdbc
spring.quartz.initialize-schema: embedded
spring.quartz.properties.org.quartz.scheduler.instanceName=MyScheduler
spring.quartz.properties.org.quartz.scheduler.instanceId=AUTO
spring.quartz.properties.org.quartz.jobStore.class=org.quartz.impl.jdbcjobstore.JobStoreTX
spring.quartz.properties.org.quartz.jobStore.driverDelegateClass=org.quartz.impl.jdbcjobstore.StdJDBCDelegate
spring.quartz.properties.org.quartz.jobStore.tablePrefix=QRTZ_
spring.quartz.properties.org.quartz.jobStore.isClustered=true
spring.quartz.properties.org.quartz.jobStore.clusterCheckinInterval=10000
spring.quartz.properties.org.quartz.jobStore.useProperties=false
spring.quartz.properties.org.quartz.threadPool.class=org.quartz.simpl.SimpleThreadPool
#threadCount=20
spring.quartz.properties.org.quartz.threadPool.threadPriority=5
spring.quartz.properties.org.quartz.threadPool.threadsInheritContextClassLoaderOfInitializingThread=true

# type-aliases-package批量设置别名作用：就是在mapper.xml文件中直接写类名，不配置就需要写类的全路径名
mybatis.type-aliases-package=cn.com.kun
mybatis.mapper-locations=classpath:mapping/*.xml
#开启驼峰命名转换
mybatis.configuration.map-underscore-to-camel-case=true

# =================== spring session ===================
#spring.session.store-type=redis
spring.session.store-type=none
# Session 过期时间，单位s（用默认的即可）
#server.session.timeout=600
# Sessions 刷新模式
spring.session.redis.flush-mode=IMMEDIATE
# Namespace for keys used to store sessions.
spring.session.redis.namespace=spring:session:kunsharedemo

# 通过排除自动配置的方式禁用spring session（不推荐）
#spring.autoconfigure.exclude=org.springframework.boot.autoconfigure.session.SessionAutoConfiguration

# =================== spring redis ===================

# spring-redis（单节点模式）
spring.redis.host=127.0.0.1
spring.redis.password=
spring.redis.port=6379

# spring-redis（集群模式）
#spring.redis.password=123456
#spring.redis.cluster.nodes=127.0.0.1:6380,127.0.0.1:6381,127.0.0.1:6382,127.0.0.1:6383,127.0.0.1:6384,127.0.0.1:6385
#spring.redis.cluster.connectionTimeout=6000
#spring.redis.cluster.soTimeout=6000
#spring.redis.cluster.maxAttempts=5
#写正确的密码（spring.redis.cluster.password不是spring要识别的，spring.redis.password才是）
#spring.redis.cluster.password=123456

## jedis的配置可加可不加，会自动定义（即使加了下面配置，不加自定义bean定义，默认实现仍是Lettuce）
## 连接池最大连接数（使用负值表示没有限制）
spring.redis.jedis.pool.max-active=1000
# 连接池最大阻塞等待时间（使用负值表示没有限制）
spring.redis.jedis.pool.max-wait=-1ms
# 连接池中的最大空闲连接
spring.redis.jedis.pool.max-idle=10
# 连接池中的最小空闲连接
spring.redis.jedis.pool.min-idle=5

# =================== jedis ===================

# 引入jedis
spring.jedis.pool.host=127.0.0.1
spring.jedis.pool.password=
spring.jedis.pool.port=6379
spring.jedis.pool.minIdle=10
spring.jedis.pool.maxIdle = 20
spring.jedis.pool.maxTotal = 500
spring.jedis.pool.numTestsPerEvictionRun = 3
spring.jedis.pool.testOnBorrow = true
spring.jedis.pool.blockWhenExhausted = false
spring.jedis.pool.testOnReturn = false

# =============== redisson  =======================
# 第一种方式
# redis（集群模式）
#spring.redis.host=127.0.0.1
#spring.redis.port=6379
#spring.redis.timeout=300s
#spring.redis.password=123456
#spring.redis.cluster.max-redirects=5000
#spring.redis.cluster.nodes=192.168.3.105:7001,192.168.3.105:7002,192.168.3.105:7003,192.168.3.105:7004,192.168.3.105:7005,192.168.3.105:7006
#spring.redis.lettuce.pool.max-active=200
#spring.redis.lettuce.pool.min-idle=15
#spring.redis.lettuce.pool.max-idle=100

# 第二种方式
#spring.redis.redisson.config=classpath:conf/redisson.yml

# 第三种方式(自定义配置属性)
# 单实例
redisson.url=127.0.0.1:6379
# 集群模式
redisson.cluster.urls=127.0.0.1:6380,127.0.0.1:6381,127.0.0.1:6382,127.0.0.1:6383,127.0.0.1:6384,127.0.0.1:6385
redisson.password=#1#2#3#4#5#6

# =================== kafka ===================
# 指定kafka 代理地址，可以多个
#spring.kafka.bootstrap-servers=192.168.3.105-------------------:9092
spring.kafka.bootstrap-servers=127.0.0.1:9092
spring.kafka.listener.missing-topics-fatal=false

# =================== kafka provider  ===================
spring.kafka.producer.retries=0
# 每次批量发送消息的数量
spring.kafka.producer.batch-size=16384
spring.kafka.producer.buffer-memory=33554432
# ack (0 不等待 1 至少等一个 -1 等所有)
spring.kafka.producer.acks=0
# 指定消息key和消息体的编解码方式
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer

#=============== kafka consumer  =======================
# 指定默认消费者group id
spring.kafka.consumer.group-id=test-hello-group

spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.enable-auto-commit=true

#============== 自定义kafka client===================
kunsharedemo.kafka.consumer.bootstrapServers=localhost:9092
#设置成同一个组ID,模拟多节点
kunsharedemo.kafka.consumer.groupId=kunsharedemo
#手动提交
kunsharedemo.kafka.consumer.enableAutoCommit=false
kunsharedemo.kafka.consumer.autoCommitIntervalMs=1000
kunsharedemo.kafka.consumer.autoOffsetReset=earliest
#每次最大拉取条数
kunsharedemo.kafka.consumer.maxPollRecords=100
#每次最大拉取内容总量
kunsharedemo.kafka.consumer.maxPartitionFetchBytes=104857600
#拉取间隔(千万不要设置太小)
#kunweb.kafka.consumer.maxPollIntervalMs=360000
kunsharedemo.kafka.consumer.maxPollIntervalMs=2000
kunsharedemo.kafka.consumer.keyDeserializer=org.apache.kafka.common.serialization.StringDeserializer
kunsharedemo.kafka.consumer.valueDeserializer=org.apache.kafka.common.serialization.StringDeserializer

kunsharedemo.kafka.producer.bootstrapServers=127.0.0.1:9092
kunsharedemo.kafka.producer.keySerializer=org.apache.kafka.common.serialization.StringSerializer
kunsharedemo.kafka.producer.valueSerializer=org.apache.kafka.common.serialization.StringSerializer

#schema registry
schema.registry.url=http://127.0.0.1:8081

# =========== kafka主题拆分组件 ==========================
#kafka.topicisolation.topicPrefix=KUNGHSU_MSG_CACHE
#kafka.topicisolation.bizTypes[0].bizKey=channel
#kafka.topicisolation.bizTypes[0].bizValues=SM01,PM01
#kafka.topicisolation.bizTypes[1].bizKey=batchFlag
#kafka.topicisolation.bizTypes[1].bizValues=BATCH,REAL
# 主题隔离实现Bean类名
#kafka.topicisolation.isolationImplBeanName=simpleModeTopicIsolationFunctionImpl
#kafka.topicisolation.isolationImplBeanName=moreChannelModeTopicIsolationFunctionImpl

# 主题拆分组件-生产者开关 默认为false
#kafka.topicisolation.producerEnabled=true
# 主题拆分组件-消费者开关 默认为false
#kafka.topicisolation.consumerEnabled=true

# =========== kafka自动切换组件 start ==========================
# 自动切换组件-生产者开关 默认为false
kafka.autoswitch.producerEnabled=true
# 自动切换组件-消费者开关 默认为false
kafka.autoswitch.consumerEnabled=false
kafka.autoswitch.controlCenterUrl=http://localhost:8080/kunsharedemo/topic-control-center/clusters
kafka.autoswitch.targetCluster=kafkaCluster1

# =========== kafka自动切换组件 end ==========================


# =============== session and jwt login  =======================
kunsharedemo.login.type=none
#kunsharedemo.login.type=session
#kunsharedemo.login.type=jwt


# =============== shardingsphere  =======================
# shardingsphere全局开关，false表示关闭，注释掉或者true表示开启
spring.shardingsphere.enabled=false
## 定义全局数据源
spring.shardingsphere.datasource.names=ds-0
# 配置数据源 ds-0
spring.shardingsphere.datasource.ds-0.type=com.alibaba.druid.pool.DruidDataSource
spring.shardingsphere.datasource.ds-0.driverClassName=com.mysql.jdbc.Driver
spring.shardingsphere.datasource.ds-0.url=jdbc:mysql://127.0.0.1:3306/test?useUnicode=true&characterEncoding=utf8&tinyInt1isBit=false&useSSL=false&serverTimezone=GMT
spring.shardingsphere.datasource.ds-0.username=root
spring.shardingsphere.datasource.ds-0.password=12345678
# 分表策略
# 分表分片健
#spring.shardingsphere.sharding.tables.tbl_student.table-strategy.inline.sharding-column=id_card
# 分表算法（自带算法，必须符合Groovy语法）
#spring.shardingsphere.sharding.tables.tbl_student.table-strategy.inline.algorithm-expression=tbl_student_$->{id_card.toLong() % 4}
# 分表分片健
spring.shardingsphere.sharding.tables.tbl_student.table-strategy.standard.sharding-column=id_card
# 自定义分表算法
spring.shardingsphere.sharding.tables.tbl_student.table-strategy.standard.precise-algorithm-class-name=cn.com.kun.apache.shardingsphere.algorithm.MyPreciseShardingAlgorithm
# 自增主键字段
spring.shardingsphere.sharding.tables.tbl_student.key-generator.column=id
# 自增主键ID 生成方案
spring.shardingsphere.sharding.tables.tbl_student.key-generator.type=SNOWFLAKE
# 是否开启 SQL解析日志
spring.shardingsphere.props.sql.show=true

# =================== Freemarker 配置 ===================
spring.freemarker.template-loader-path=classpath:/templates/
spring.freemarker.cache=false
spring.freemarker.charset=UTF-8
spring.freemarker.check-template-location=true
spring.freemarker.content-type=text/html
spring.freemarker.expose-request-attributes=true
spring.freemarker.expose-session-attributes=false
spring.freemarker.request-context-attribute=request
#必须指定路径规则
spring.freemarker.prefix=/
spring.freemarker.suffix=.ftl

# =================== xxl-job 配置 ===================
### xxl-job admin address list, such as "http://address" or "http://address01,http://address02"
xxl.job.admin.addresses=http://127.0.0.1:8061/xxl-job-admin

### xxl-job executor address
xxl.job.executor.appname=xxl-job-executor-kunsharedemo
xxl.job.executor.ip=
xxl.job.executor.port=9999

### xxl-job, access token
xxl.job.accessToken=

### xxl-job log path
xxl.job.executor.logpath=/data/applogs/xxl-job/jobhandler
### xxl-job log retention days
xxl.job.executor.logretentiondays=30

# =================== elasticsearch 配置 ===================
#spring.data.elasticsearch.cluster-name=elasticsearch
#spring.data.elasticsearch.cluster-nodes=192.168.3.105:930000
#spring.data.elasticsearch.repositories.enabled=true
# es服务未启动时，设置为false,禁用repositories接口的初始化（避免启动报错）
#spring.data.elasticsearch.repositories.enabled=false
#spring.elasticsearch.rest.uris=http://192.168.3.105:9200
#spring.elasticsearch.rest.username=elastic
#spring.elasticsearch.rest.password=phoenix2019$


# =================== 全局的技术组件开关 ===================
# 加一层自定义的开发，控制是否启用@EnableTask注解
#kunsharedemo.springcloud-task.enabled=false

# 是否开启手动数据源
# 只有多数据源时才需要开启，否则用自动配置的足够了，所以默认禁用
kunsharedemo.maindb.datasource.enabled=false
#kunsharedemo.maindb.datasource.enabled=true

# 自定义开关：控制@EnableRedisHttpSession是否生效
kunsharedemo.redis-session.enabled=false

#是否启用fastjson做全局json转换器
kunsharedemo.fastjson.enabled=false

# redis集群模式单节点模式切换开关（设置为false表示关闭集群模式）
kunsharedemo.rediscommon.cluster.enabled=false

# 自定义开关：控制Jedis是否生效
kunsharedemo.jedis.enabled=false

#kunsharedemo.redisson.enabled=false
#是否开启redisson集群模式
kunsharedemo.redisson.cluster.enabled=false
#kunsharedemo.redisson.cluster.enabled=true

# Quartz（禁用Quartz）
kunsharedemo.quartz.enabled=false

# xxl-job（禁用）
kunsharedemo.xxl-job.enabled=false

# kafka client
# 需要用Kafka时注释，不用Kafka时放开注释
#kunsharedemo.kafkaclients.enabled=false

# 排除自动配置
# 禁用redisson自动配置（不相当于不集成redisson）,注释掉表示开启自动配置(右斜杠分隔行)
spring.autoconfigure.exclude=org.springframework.boot.autoconfigure.quartz.QuartzAutoConfiguration\
  ,org.redisson.spring.starter.RedissonAutoConfiguration\
  ,org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchRepositoriesAutoConfiguration\
  ,org.springframework.boot.autoconfigure.elasticsearch.rest.RestClientAutoConfiguration
#  ,com.alibaba.druid.spring.boot.autoconfigure.DruidDataSourceAutoConfigure
#  ,org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration

## 排除自动配置
## 禁用redisson自动配置（不相当于不集成redisson）,注释掉表示开启自动配置(右斜杠分隔行)
#spring.autoconfigure.exclude=org.redisson.spring.starter.RedissonAutoConfiguration\
#  ,org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchRepositoriesAutoConfiguration\
#  ,org.springframework.boot.autoconfigure.elasticsearch.rest.RestClientAutoConfiguration
##  ,com.alibaba.druid.spring.boot.autoconfigure.DruidDataSourceAutoConfigure
##  ,org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration

# =================== MemoryCache内存缓存机制 ===================
memorycache.enabled=true

# 内存缓存组件使用的角色(All\Maintain\Apply\None)
#memorycache.role=None
#memorycache.role=Maintain
#memorycache.role=Apply
memorycache.role=All


# 内存缓存组件异步线程检测间隔，单位ms 建议设置为30000
#memorycache.apply.detect-thread-sleep-time=120000

#memorycache.maintain.clusterName=c1
#memorycache.maintain.clusterList=c1,c2
#是否为多活Redis
#memorycache.maintain.multiRedis=false

# =================== MemoryCache内存缓存机制 ===================
# 用于表示本节点所归属的集群
dbclusterlock.clusterCode=c1

# =================== 自定义限流机制 ===================
ratelimit.enabled=true
ratelimit.global-rate=200
# 向前限流
# url地址不含上下文
ratelimit.forward.zuulDemoController.default-rate=150
ratelimit.forward.zuulDemoController.api-limit[0].api=/zuul-demo/test1
ratelimit.forward.zuulDemoController.api-limit[0].api-rate=800
ratelimit.forward.zuulDemoController.api-limit[1].api=/zuul-demo/test2
ratelimit.forward.zuulDemoController.api-limit[1].api-rate=30
ratelimit.forward.zuulDemoController.api-limit[2].api=/zuul-demo/test3
ratelimit.forward.zuulDemoController.api-limit[2].api-rate=50
ratelimit.forward.rateLimitDemoController.default-rate=150
ratelimit.forward.rateLimitDemoController.api-limit[0].api=/zuul-demo/test1
ratelimit.forward.rateLimitDemoController.api-limit[0].api-rate=800
ratelimit.forward.rateLimitDemoController.api-limit[1].api=/zuul-demo/test2
ratelimit.forward.rateLimitDemoController.api-limit[1].api-rate=30
ratelimit.forward.rateLimitDemoController.api-limit[2].api=/zuul-demo/test3
ratelimit.forward.rateLimitDemoController.api-limit[2].api-rate=50
# 向后限流
ratelimit.backward.sendmsg.default-rate=150
ratelimit.backward.sendmsg.limit-item[0].name=DX
ratelimit.backward.sendmsg.limit-item[0].rate=100
ratelimit.backward.sendmsg.limit-item[1].name=WX
ratelimit.backward.sendmsg.limit-item[1].rate=2

# =================== 自定义限流机制-hystrix扩展实现 ===================
hystrix-ratelimit.enabled=true
# 向后限流
hystrix-ratelimit.business-scene-limit.sendmsg.default-rate=150
hystrix-ratelimit.business-scene-limit.sendmsg.limit-item[0].name=DX
hystrix-ratelimit.business-scene-limit.sendmsg.limit-item[0].rate=10
hystrix-ratelimit.business-scene-limit.sendmsg.limit-item[1].name=WX
hystrix-ratelimit.business-scene-limit.sendmsg.limit-item[1].rate=2

# =================== 线程池配置 ===================
custom.threadPool.items.myBizCommonExecutor.corePoolSize=2
custom.threadPool.items.myBizCommonExecutor.maxPoolSize=4
custom.threadPool.items.myBizCommonExecutor.queueCapacity=10

# =================== redo组件 ===================
kunghsu.redo.scheduleRate=30

# =================== batch框架扩展 ===================
# 异常跳过百分比阈值：例如允许1%容错，填1，允许10%就填10.允许百分百则填100.
kunghsu.batch.skipRatioThreshold=98

# =================== 业务参数 ===================
nbaplay.number=1
nbaplay.level=super star2


